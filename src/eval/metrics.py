from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix

def classification_report(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec, recall, f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average='macro', zero_division=0
    )
    cm = confusion_matrix(y_true, y_pred)

    return {
        "accuracy": acc,
        "precision": prec,
        "recall": recall,
        "f1_score": f1,
        "confusion_matrix": cm.tolist()
    }
